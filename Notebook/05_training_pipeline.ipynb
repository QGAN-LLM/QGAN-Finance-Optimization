# QGAN Training Pipeline with Ethical Constraints
# Complete training pipeline with monitoring and ethical compliance

import sys
sys.path.append('..')

import pandas as pd
import numpy as np
from pathlib import Path
import yaml
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import warnings
warnings.filterwarnings('ignore')

# Custom imports
from src.quantum.qgan import EthicalQGAN
from src.training.ethical_trainer import PurposeLimitedTrainer
from src.training.pipeline import QGANTrainingPipeline
from src.evaluation.metrics import EthicalMetricsCalculator
from src.utils.logger import setup_logger

print("=" * 80)
print("QGAN TRAINING PIPELINE WITH ETHICAL CONSTRAINTS")
print("=" * 80)
print("Principle: Full training with monitoring and ethical compliance")
print("Purpose: Train QGAN refiner for LLM optimization\n")

# Setup
logger = setup_logger('qgan_training')
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Load configurations
with open('../configs/training_config.yaml', 'r') as f:
    train_config = yaml.safe_load(f)

with open('../configs/model_config.yaml', 'r') as f:
    model_config = yaml.safe_load(f)

# ============================================================================
# 1. PREPARE TRAINING DATA
# ============================================================================
print("\n1. PREPARING TRAINING DATA")
print("-" * 40)

# Load processed data
data_dir = Path("../data/processed")
train_data = pd.read_parquet(data_dir / "train_data.parquet")
test_data = pd.read_parquet(data_dir / "test_data.parquet")

print(f"Training data shape: {train_data.shape}")
print(f"Test data shape: {test_data.shape}")

# Prepare features (aligned with baseline models)
feature_cols = [
    'ret_1', 'ret_2', 'ret_3',
    'ta_rsi_14', 'ta_macd',
    'vol_atr_14', 'vol_realized_20',
    'time_hour', 'time_is_weekend'
]

available_features = [f for f in feature_cols if f in train_data.columns]
print(f"Using {len(available_features)} features for training")

X_train = train_data[available_features].values
X_test = test_data[available_features].values

# Scale features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create PyTorch datasets
train_tensor = torch.FloatTensor(X_train_scaled).to(device)
test_tensor = torch.FloatTensor(X_test_scaled).to(device)

train_dataset = TensorDataset(train_tensor)
test_dataset = TensorDataset(test_tensor)

train_loader = DataLoader(train_dataset, 
                         batch_size=train_config['training']['batch_size'],
                         shuffle=True)
test_loader = DataLoader(test_dataset,
                        batch_size=train_config['training']['batch_size'],
                        shuffle=False)

print(f"\nData loaders created:")
print(f" Training batches: {len(train_loader)}")
print(f" Test batches: {len(test_loader)}")
print(f" Batch size: {train_config['training']['batch_size']}")

# ============================================================================
# 2. INITIALIZE ETHICAL QGAN
# ============================================================================
print("\n2. INITIALIZING ETHICAL QGAN")
print("-" * 40)

# Create QGAN configuration with ethical constraints
qgan_config = {
    'n_qubits': model_config['qgan']['n_qubits'],
    'input_dim': len(available_features),
    'output_bounds': model_config['qgan']['ethical_constraints']['output_bounds'],
    'ethical_constraints': {
        'max_volatility': 0.04,
        'prevent_extreme_values': True,
        'anomaly_detection': True
    }
}

qgan_model = EthicalQGAN(qgan_config).to(device)
print("QGAN Model Architecture:")
print(f" Quantum Generator: {qgan_model.generator}")
print(f" Classical Discriminator: {qgan_model.discriminator}")
print(f" Ethical constraints: {qgan_config['ethical_constraints']}")

# Test initial generation
with torch.no_grad():
    test_samples = qgan_model.generate_ethical_samples(10, device)
    ethical_report = qgan_model.get_ethical_report(test_samples)

print("\nInitial Ethical Generation Test:")
for key, value in ethical_report.items():
    if isinstance(value, bool):
        status = "✓" if value else "✗"
        print(f" {status} {key}: {value}")
    else:
        print(f" {key}: {value:.4f}")

# ============================================================================
# 3. SETUP TRAINING PIPELINE WITH ETHICAL MONITORING
# ============================================================================
print("\n3. SETUP TRAINING PIPELINE")
print("-" * 40)

# Initialize ethical trainer
trainer_config = {
    'data_usage': {
        'permitted_purposes': train_config['training'].get('permitted_purposes', 
                                                          ['model_training', 'benchmarking']),
        'prohibited_purposes': ['repurposing', 'commercial_use']
    },
    'use_wandb': train_config['logging'].get('use_wandb', False),
    'checkpoint_dir': Path(train_config['logging'].get('checkpoint_dir', '../checkpoints'))
}

trainer = PurposeLimitedTrainer(qgan_model, trainer_config)

# Initialize training pipeline
pipeline = QGANTrainingPipeline(
    model=qgan_model,
    trainer=trainer,
    config=train_config,
    device=device
)

print("Pipeline components:")
print(f" ✓ Ethical trainer with purpose limitation")
print(f" ✓ Checkpointing every {train_config['training'].get('checkpoint_frequency', 100)} steps")
print(f" ✓ Early stopping patience: {train_config['training'].get('early_stopping_patience', 10)}")
print(f" ✓ Max training time: {train_config['training'].get('max_training_time', '24:00:00')}")

# ============================================================================
# 4. EXECUTE TRAINING
# ============================================================================
print("\n4. EXECUTING QGAN TRAINING")
print("-" * 40)

# Start training
training_results = pipeline.train(
    train_loader=train_loader,
    test_loader=test_loader,
    epochs=train_config['training'].get('epochs', 100)
)

print(f"\nTraining completed:")
print(f" Total epochs: {len(training_results['train_losses'])}")
print(f" Best epoch: {training_results['best_epoch']}")
print(f" Best loss: {training_results['best_loss']:.4f}")
print(f" Early stopped: {training_results['early_stopped']}")

# ============================================================================
# 5. TRAINING MONITORING & VISUALIZATION
# ============================================================================
print("\n5. TRAINING MONITORING")
print("-" * 40)

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# Training losses
axes[0, 0].plot(training_results['train_losses'], label='Generator Loss', alpha=0.7)
axes[0, 0].plot(training_results['discriminator_losses'], label='Discriminator Loss', alpha=0.7)
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Loss')
axes[0, 0].set_title('Training Losses')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Ethical scores during training
if 'ethical_scores' in training_results:
    axes[0, 1].plot(training_results['ethical_scores'], color='green', alpha=0.7)
    axes[0, 1].axhline(y=0.9, color='r', linestyle='--', alpha=0.5, label='Target (0.9)')
    axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Ethical Score')
axes[0, 1].set_title('Ethical Compliance During Training')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Generated samples distribution
with torch.no_grad():
    final_samples = qgan_model.generate_ethical_samples(1000, device).cpu().numpy()

axes[0, 2].hist(final_samples.flatten(), bins=50, alpha=0.7, edgecolor='black')
axes[0, 2].axvline(x=qgan_config['output_bounds'][0], color='r', linestyle='--', alpha=0.7)
axes[0, 2].axvline(x=qgan_config['output_bounds'][1], color='r', linestyle='--', alpha=0.7)
axes[0, 2].set_xlabel('Generated Value')
axes[0, 2].set_ylabel('Frequency')
axes[0, 2].set_title('Final Generated Distribution')
axes[0, 2].grid(True, alpha=0.3)

# Validation losses
if 'val_losses' in training_results:
    axes[1, 0].plot(training_results['val_losses'], color='orange', alpha=0.7)
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('Validation Loss')
    axes[1, 0].set_title('Validation Loss')
    axes[1, 0].grid(True, alpha=0.3)

# Learning rate schedule (if used)
if 'learning_rates' in training_results:
    axes[1, 1].plot(training_results['learning_rates'], color='purple', alpha=0.7)
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Learning Rate')
    axes[1, 1].set_title('Learning Rate Schedule')
    axes[1, 1].grid(True, alpha=0.3)

# Training time per epoch
if 'epoch_times' in training_results:
    axes[1, 2].plot(training_results['epoch_times'], color='brown', alpha=0.7)
    axes[1, 2].set_xlabel('Epoch')
    axes[1, 2].set_ylabel('Time (seconds)')
    axes[1, 2].set_title('Training Time per Epoch')
    axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('../results/qgan_training_monitoring.png', dpi=150, bbox_inches='tight')
plt.show()

# ============================================================================
# 6. ETHICAL COMPLIANCE AUDIT
# ============================================================================
print("\n6. ETHICAL COMPLIANCE AUDIT")
print("-" * 40)

# Generate final ethical report
final_samples = qgan_model.generate_ethical_samples(10000, device)
final_report = qgan_model.get_ethical_report(final_samples)

print("Final Ethical Generation Report:")
print("-" * 60)
for key, value in final_report.items():
    if isinstance(value, bool):
        status = "✓ PASS" if value else "✗ FAIL"
        print(f"{status:<10} {key.replace('_', ' ').title()}")
    else:
        print(f" {key.replace('_', ' ').title():<25}: {value:.6f}")

# Data usage audit
trainer.save_audit_trail('../results/ethical_audit_trail.json')
print(f"\n✓ Data usage audit saved to: ../results/ethical_audit_trail.json")

# Calculate energy consumption (estimate)
if 'epoch_times' in training_results:
    total_training_time = sum(training_results['epoch_times'])
    energy_consumption = total_training_time / 3600 * 0.3 # Assume 300W GPU
    print(f"✓ Estimated energy consumption: {energy_consumption:.2f} kWh")
    print(f"✓ Within energy budget: {energy_consumption <= model_config['qgan']['ethical_constraints'].get('energy_budget', 100)}")

# ============================================================================
# 7. SAVE TRAINED MODEL WITH METADATA
# ============================================================================
print("\n7. SAVING TRAINED MODEL")
print("-" * 40)

# Create model metadata
metadata = {
    'training_date': datetime.now().isoformat(),
    'training_config': train_config,
    'model_config': qgan_config,
    'training_results': {
        'final_epoch': len(training_results['train_losses']),
        'best_loss': float(training_results['best_loss']),
        'best_epoch': training_results['best_epoch'],
        'early_stopped': training_results['early_stopped']
    },
    'ethical_compliance': final_report,
    'data_usage_summary': {
        'total_batches': len(train_loader) * len(training_results['train_losses']),
        'total_samples': len(train_loader.dataset) * len(training_results['train_losses'])
    },
    'purpose_limitation': {
        'allowed_uses': ['research', 'benchmarking', 'academic_publication'],
        'prohibited_uses': ['commercial', 'trading', 'redistribution'],
        'expiration_date': '2025-12-31'
    }
}

# Save model
model_dir = Path("../results/models/qgan")
model_dir.mkdir(parents=True, exist_ok=True)

# Save PyTorch model
torch.save({
    'model_state_dict': qgan_model.state_dict(),
    'metadata': metadata,
    'scaler_state': scaler
}, model_dir / "qgan_model.pth")

print(f"✓ Model saved to: {model_dir}/qgan_model.pth")

# Save metadata separately
import json
with open(model_dir / "model_metadata.json", 'w') as f:
    json.dump(metadata, f, indent=2, default=str)

print(f"✓ Model metadata saved to: {model_dir}/model_metadata.json")

# Save training history
training_history = pd.DataFrame({
    'epoch': range(1, len(training_results['train_losses']) + 1),
    'train_loss': training_results['train_losses'],
    'discriminator_loss': training_results['discriminator_losses'],
    'ethical_score': training_results.get('ethical_scores', [None] * len(training_results['train_losses']))
})

training_history.to_csv(model_dir / "training_history.csv", index=False)
print(f"✓ Training history saved to: {model_dir}/training_history.csv")

print("\n" + "=" * 80)
print("QGAN TRAINING PIPELINE COMPLETE")
print("=" * 80)
print(f"✓ Trained QGAN for {len(training_results['train_losses'])} epochs")
print(f"✓ All ethical constraints applied and validated")
print(f"✓ Model saved with comprehensive metadata")
print(f"✓ Ready for validation against baseline models")

